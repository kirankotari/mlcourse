{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\" />\n",
    "    \n",
    "## [mlcourse.ai](https://mlcourse.ai) â€“ Open Machine Learning Course \n",
    "### <center> Author: Name as in the rating, ODS Slack nickname\n",
    "    \n",
    "## <center> Tutorial\n",
    "### <center> \"Your topic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "**Rules:**\n",
    " - It must be a tutorial (reproducible Jupyter notebook, ipynb file), i.e you should teach some skills, do not just express your ideas on some theoretical concept\n",
    " - It is not just a translation of somebody else's material. You can borrow some stuff, but with fair links/citations\n",
    " - The prerequisite for reading your tutorial should be basic ML as taught in [mlcourse.ai](https://mlcourse.ai). Do not write in-depth articles about neural nets, probabilistic programming, Bayesian approach, reinforcement learning etc. - topics like these need a thorough approach. That is, sure, you can write articles like that, but not in the format of [mlcourse.ai](https://mlcourse.ai) tutorials. On the other hand, it's hardly worth making a tutorial too simple (e.g., to take some library and demonstrate only a couple of methods from it)\n",
    " - A typical tutorial shall be 30-60 minutes to read and digest (however, here exceptions are possible)\n",
    " - Check out a [list](https://github.com/Yorko/mlcourse.ai/wiki/Individual-projects-and-tutorials-(in-Russian)) of published tutorials from previous runs of this course (in Russian). Yes, it's in Russian but Google Translate can kind of give you an insight, and topic that are already covered. For those who already passed the course: definitely, translating somebody else's (or your own) tutorial into English is not going to work\n",
    "\n",
    "Here are a dozen of sample topics (but this is a just as an example, you can/should come up with your own):\n",
    " - data collection, crawling with, working with XML, JSON and so on.\n",
    " - overview of dask library\n",
    " - overview of Bokeh or another viz library\n",
    " - decision trees with statistical tests in the nodes\n",
    " - review of H2O library\n",
    " - poisson/quantile or another type of regression\n",
    " - automatization of machine learning, AutoML, Teapot\n",
    " - interpretability of ML - LIME, reducing of Forests to Trees\n",
    " - review of some clustering method (with motivation, why it is needed)\n",
    " - dimentionality reduction for visualization (there are some methods besides t-SNE, e.g. from manifold learning family)\n",
    " - fastText\n",
    " - methods of imputing missing data\n",
    " - description of some Kaggle tricks\n",
    " - counters in supervised learning tasks: WOE, smoothed likelihood and other methods of feature engineering from the target\n",
    " - there is much more in Scikit-learn that we didn't cover (e.g. different methods of feature selection, feature hashing; you cover NestedCV or elastic net, for instance)\n",
    " - methods of tree visualization in Python (other than standard graphviz)\n",
    " - something about statistics, but such that a general audience will understand\n",
    " - something that better covers the course material, e.g. a broader review of Vowpal Wabbit \n",
    " - data analysis with bash\n",
    " - etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to publish: \n",
    "  1. First of all, choose a unique topic and register it in the [Google doc](https://docs.google.com/spreadsheets/d/15qao-tn6V7JXy2bWUasWy-yOXDm8xW8ZtPXfdJnO-v4/edit?usp=sharing)\n",
    "  2. Make a Pull Request with your tutorial in a form of a Jupyter notebook [here](https://github.com/Yorko/mlcourse.ai/tree/master/jupyter_english/tutorials). Respect the repo structure: please put images to img, ipynb file to `jupyter_english/tutorials`. Do not commit data to our repo. Instead, upload your data somewhere, and share a link\n",
    "  3. When your Pull Request is accepted, you need to make an [nbviewer](http://nbviewer.jupyter.org/) link for your ipynb file and share the link in the #mlcourse_ai Slack channel with a short description of the tutorial. You also need to add the *#tutorial_contest* tag, It's obligatory, otherwise, the tutorial will be ignored.\n",
    "  4. If you don't cope with these simple rules, your tutorial is not taken into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
=======
    "## Rules\n",
    "Read carefully the [roadmap](https://mlcourse.ai/roadmap)!\n",
    "This time you are asked to publish a tutorial as a Kaggle Kernel in [mlcourse.ai Dataset](https://www.kaggle.com/kashnitsky/mlcourse).\n",
    "\n",
    "\n",
    "## Exemplar topics  \n",
    "Here are a dozen of exemplar topics (but this is a just as an example, you can/should come up with your own):\n",
    "\n",
    "#### Pandas & Data Analysis\n",
    "- Data collection, crawling, working with XML, JSON etc.\n",
    "- Working with big DataFrames, Dask. \n",
    "- Optimizing memory usage while working with NumPy, Pandas and pure Python\n",
    "- Working with JSON and XML in Pandas\n",
    "- When to use SQL with Pandas or just SQL\n",
    "- Feather data format\n",
    "- Reducing memory consumption while analyzing data: tips & tricks\n",
    "- Data analysis with bash (utilizing extremely efficient command line utils)\n",
    " \n",
    "#### Visualization\n",
    " - Overview of Bokeh or another viz library\n",
    " - Working with geo-spatial data in Python\n",
    " - Creating animations for data analysis\n",
    " - Tree visualization in Python (smth more than standard graphviz)\n",
    " - Dimentionality reduction for visualization (there are some methods besides t-SNE, e.g. UMAP)\n",
    " \n",
    "#### Decision trees & kNN\n",
    " - Decision trees with statistical tests in the nodes\n",
    " - Overview of H2O library\n",
    " - kNN in production systems: Annoy \n",
    " - kNN as a strong baseline in recommender systems\n",
    " \n",
    "#### Linear models\n",
    "\n",
    " - Poisson/quantile or another type of regression\n",
    " - Multi-label classification\n",
    " - Efficient implementation of linear models (based QR-decomposition or similar)\n",
    " - Median and quantile regression\n",
    " - Interpreting linear models: SHAP, eli5\n",
    "\n",
    "#### Features & Validation\n",
    " - Counters in supervised learning tasks: WOE, smoothed likelihood and other methods of feature engineering based on the target feature\n",
    " - there is much more in Scikit-learn that we didn't cover (NestedCV, GroupKFold etc)\n",
    "\n",
    "#### Bagging and Random Forest\n",
    " - Interpreting RF by reducing forests to trees\n",
    " - Compressing random forests\n",
    " - Various heuristics for assessing feature importance in forests and boosting\n",
    " \n",
    "#### Unsupervised learning\n",
    " - Review of some clustering method (with motivation, why it is needed)\n",
    " - Efficient PCA implementation, Randomized PCA, online PCA\n",
    " - Unsupervised learning in real tasks\n",
    " - Word2Vec applied to sequential data (even website sessions like in the \"Alice\" competition)\n",
    "\n",
    "#### SGD & Vowpal Wabbit\n",
    " - Something that better covers the course material, e.g. a broader review of Vowpal Wabbit \n",
    " - Matrix factorization, FMs and Vowpal Wabbit implementation\n",
    " - FTRL algorithm: Follow the regularized leader\n",
    "\n",
    "#### Time series\n",
    " - Predicting multiple time series at the same time\n",
    " - Detecting anomalies in time series\n",
    " \n",
    "#### Boosting\n",
    " - CatBoost overview + examples where it works really well \n",
    " - Overview of the H2O library\n",
    " - Gradient boosting and GPU speedup\n",
    "\n",
    "#### Other\n",
    " - A/B tests and interleaving\n",
    " - Bayesian methods of hyperparameter optimization\n",
    " - Versioning datasets (ex. DVC.org)\n",
    " - Optimizing non-trivial metrics: tips & tricks\n",
    " - Closer to business metrics: uplift modelling (pylift)"
   ]
>>>>>>> ec8ebec14b4b3ceea0972a86b7885ff3b15d207d
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.6.6"
=======
   "version": "3.7.1"
>>>>>>> ec8ebec14b4b3ceea0972a86b7885ff3b15d207d
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
